---
title: "VerifAI"
description: "Fake News Detector using BERT model and transfer learning"
custom_link_label: "Live Preview"
custom_link: "https://demourl.com/"
updatedDate: "Sep 15 2022"
pricing: "Hackathon"
badge: "Featured"
checkoutUrl: "https://checkouturl.com/"
heroImage: "/itemPreview.webp"
---

VerifAI, is a fake news detection model which utilizes the pre-trained BERT (bidirectional encoder representations from transformers) model and transfer learning. VerifAI uses Flask, a python web framework, to deploy a web app that allows users to check the likelihood of each line from a news article being fake. The app takes in a news article/heading input from the user and processes the input text by breaking it down into individual lines or sentences. Each line is then fed into the BERT model. BERT's natural language processing capabilities allow it to understand the context and semantics of each line, which is crucial for accurately determining the veracity of the information. Since BERT is pre-trained on a vast corpus of text, it already has a significant understanding of language. However, through transfer learning, the model has been further fine-tuned on datasets specifically related to news, misinformation, and fact-checking, enhancing its ability to detect fake news. For each line, the model assesses the likelihood of it being fake presented as a percentage with 0 being very unlikely to be fake and 100 being very likely to be fake. The app then displays the results to the user, showing which parts of the article might be misleading or false. This line-by-line breakdown helps users understand specific areas of concern within the article.

How we built it
We used various Python libraries, including NumPy, Pandas, PyCaret, Transformers (from Hugging Face), Matplotlib, and several modules from Scikit-Learn. These libraries are essential for data manipulation, model training, and evaluation. Then we performed data pre-processing, Split the dataset into training, validation, and test sets using the train_test_split. Then we loaded a pre-trained BERT model ('bert-base-uncased') and its tokenizer using Hugging Face Transformers. Then we had efficient training with batch processing. We then freeze the layers of the BERT model to prevent them from being updated during training. Freezing the layers of the BERT model ensures that the pre-trained knowledge is not lost during the training process. This step is crucial for transfer learning. Only the classification layers on top of the BERT model will be fine-tuned. Next we went on to define a custom neural net called 'BERT_Arch' that takes the BERT model, adds dropout layers, activation functions, and fully connected layers. This is designed for binary classification and the model uses a log-softmax activation for the output layer. The architecture includes dropout layers to prevent overfitting and employs a log-softmax activation function in the output layer for probability-based classification. We then trained the model, evaluated classification metrics (such as precision, recall, and F1-score) and finally performed the fake news prediction. We then set up a Flask web application using HTML to display the project.

What's next for VerifAI?
In the future we really want to fine-tune the BERT model and work with a larger dataset to understand more news articles. We were also thinking of the expansion of some of the features including more than just text like images. And possibly including user feedback to help refine the model to correct biases and improve accuracy. And weâ€™d love to create a mobile application to make it easier for people to use to fix and gauge issues with fake news. We're determined to take our project to the next level and make a positive impact on the fight against fake news and misinformation. We're excited to see where this journey takes us and the opportunities it presents for learning and growth.
